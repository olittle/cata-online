type=java
job.class=com.linkedin.sage.indexing.LiarIndexingJob
dependencies=jymbii-batch-job-postfeast

hadoop.job.ugi=${hadoop.job.ugi.cmd}
is.local=${is.local}
force.output.overwrite=${force.output.overwrite}
debug.level=${debug.level}

id.range.based.partitioner.id.ranges=${jobs.id.range.based.partitioner.id.ranges}
num.index.shards=${jobs.num.index.shards}

input.paths=${jobs_postFeast.dir}
final.index.dir=${jobs_index.tmp.output.dir}

liar.entity.type=jobs
#liar.entity.filter.class=com.linkedin.sage.indexing.LiarJobInfoEntityFilter
liar.entity.filter.class=
index.ram.buffer.size.mb=${index.ram.buffer.size.mb}
index.max.buffered.docs=${index.max.buffered.docs}

notify.emails=${indexing.contact}
azkaban.should.proxy=${azkaban.should.proxy}
user.to.proxy=${user.to.proxy}

hadoop-conf.mapred.job.queue.name=${hadoop_queue}
hadoop-conf.mapred.task.timeout=${mapred.task.timeout}
hadoop-conf.mapred.min.split.size=2147483648
hadoop-conf.dfs.umaskmode=002
hadoop-conf.mapred.child.java.opts=-Xmx1G -Djava.net.preferIPv4Stack=true -XX:+UseCompressedStrings -XX:+UseCompressedOops

hdfs.default.classpath.dir=${remote.library.path}
#classpath=${local.classpath}
param.OUTPUT=${dcrr.base}
